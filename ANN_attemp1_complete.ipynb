{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_attemp1_complete.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tcYQLXd00P44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "711231d5-c43c-44d8-ea24-366a5c662cfd"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/tfcontent')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /tfcontent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WtDVQ3I6UCw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "32ade815-c15d-467d-fe32-9af8303e98ed"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "data=pd.read_csv(r'/tfcontent/My Drive/Churn_Modelling.csv')\n",
        "data.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "I0ujTmETz2Iy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4671ed74-b650-4591-a19f-9f02e5ee7e62"
      },
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "wIbqCn3VUW9c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#including variables that might have impact on the variable on the dependent variable\n",
        "x=data.iloc[:,3:14].values#it will acess variables from 3 to 12\n",
        "#to acess values upto 12 indexe's we add the upperbound bcz upperbound is excluded in python\n",
        "y=data.iloc[:,13:].values# accessing the Y variable which is the 13th index which tells us how many customers will leave\n",
        "# here we imported the data that we need to use to train the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GI_0is6f0G__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a7f93e43-8e88-49cb-ed3a-923a2aa27427"
      },
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 11)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pzHNJEPkUr9P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Encoding cateogrical data #2var needed to be encoded thus we used LableEncoder twice\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "labelEncoder_x_1=LabelEncoder()\n",
        "x[:,1]=labelEncoder_x_1.fit_transform(x[:,1])#code till here encoded country into 0,1,2\n",
        "labelEncoder_x_2=LabelEncoder()\n",
        "x[:,2]=labelEncoder_x_2.fit_transform(x[:,2])#his 2 lines will encode female index into 0,1\n",
        "# onehotencoder= OneHotEncoder()\n",
        "# x=onehotencoder.fit_transform(x).toarray()\n",
        "# x=x[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "58hGevo__rI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QfzqDdsOU-DC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " #splitting dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state= 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63P__non_WyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape) \n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D_kKIuefYVkB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQ_PrbxmVRFH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #feature scaling #It is done when we have lot of variables and we don't one some variables to dominate the others\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# sc=StandardScaler()\n",
        "# cv = x_train.reshape(1,-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mCvvNGZ-Yof7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cv.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVfSlPFaazF9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# x_train=x_train.reshape(1,-1)\n",
        "# x_test=x_test.reshape(1,-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p3f_Nl5hYyNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dde7f304-482d-47a5-dd97-2c63397e86f0"
      },
      "cell_type": "code",
      "source": [
        "#feature scaling #It is done when we have lot of variables and we don't one some variables to dominate the others\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "x_train=sc.fit_transform(x_train)\n",
        "x_test=sc.fit_transform(x_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rWPM93nRgNyQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating ANN\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense#DENSE function will add weights on its own #weights are then adjusted by learning rate parimeter on its own\n",
        "from keras.layers import Dropout# this is to prevent overfitting, it should be used in the end if the mode is overfitting and it can be applied to all the layers or some layers but if the overfitting is a lot then adding dropout to all the layers is a much better choice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ilYASWdnhgoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Classifier=Sequential()#Here we creates our ANN whose job is to classify who will stay and who won't\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qtavwCcDiZf_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "afc798b3-5aa6-476f-8e98-6180afd948af"
      },
      "cell_type": "code",
      "source": [
        "#Adding Input layer and hidden layer & both the layers are added using the dense function\n",
        "\n",
        "#output_dim will telll us how many hidden layers to add & there are 2 techniques 1st is taking avg of input +output nodes and 2nd is using k fold \n",
        "#init=uniform will add weights on its own uniformly starting from the closest value close to 0\n",
        "#activitation='relu' is used  to activate both rectifier activation and sigmoid actication function\n",
        "#input_dim=11 is a conpulsary argument that will tell the ANN how many inut variables are there \n",
        "Classifier.add(Dense(output_dim=6,init='uniform', activation='relu', input_dim=11))\n",
        "\n",
        "#p tells us how many fraction if newrons we want to drop/disable\n",
        "Classifier.add(Dropout(p=0.1))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "h_ILcHH7CRd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5c9a5c98-1979-435a-ffe4-81a56a77a9ee"
      },
      "cell_type": "code",
      "source": [
        "#adding 2nd hidden layer\n",
        "Classifier.add(Dense(output_dim=6,init='uniform', activation='relu'))\n",
        "Classifier.add(Dropout(p=0.1))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6O-HdQqYCdGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d5d03e89-5acc-4fb1-ee36-e8dd43ebfbb5"
      },
      "cell_type": "code",
      "source": [
        "#creating the output layer\n",
        "\n",
        "#output_dim=1 bcz the output layer is a binary classification\n",
        "#activation=sigmoid since sigmoid function is better for classification of  a yes/no kinda output\n",
        "Classifier.add(Dense(output_dim=1,init='uniform', activation='sigmoid'))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "SacspNDBFCsa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Compiling ANN\n",
        "\n",
        "#In order to get optimal output we need to make sure the ann is adding the best weights using scaristic gradiant descend and adam is the best scaristic gradient descend optimiser\n",
        "##optimiser='adam' will gradually keep increasing the weights inorder to get the best output\n",
        "##loss function will help in fnding the optimal weights, loss function will find the difference between the actual value and the expexted value and will calulate using sq difference/2\n",
        "#loss='binary_crossentropy' is used since the output is going to be binary\n",
        "#if we didnt have a binary output we would have used loss='cateogrical_crossentropy'\n",
        "##matrics is used to evaluate the model\n",
        "#wehn weights are increased after each epoch model uses matrics to improve the models performance\n",
        "#model needed multiple matrics but by adding [] we convert it into list and tell the model to focus only on accuracy\n",
        "Classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "# optimizer=Adam(lr=0.0001,decay=0.0001)\n",
        "# Classifier.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "98qknWetxM5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x_train.shape\n",
        "# y_train.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vq_F0amoyF8n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NsLDGC2UZgZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3536
        },
        "outputId": "b6982087-366b-4f24-c8a4-971bc43be10f"
      },
      "cell_type": "code",
      "source": [
        "#Connecting ANN to the training set\n",
        "#batch size is the no of obs after which we update the weights\n",
        "#epoch is when the whole training set passes through an ANN\n",
        "\n",
        "Classifier.fit(x_train,y_train,batch_size=10, nb_epoch=100)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 5s 565us/step - loss: 0.2890 - acc: 0.8476\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 4s 557us/step - loss: 0.1079 - acc: 1.0000\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 4s 552us/step - loss: 0.0718 - acc: 1.0000\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 0.0483 - acc: 1.0000\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 0.0331 - acc: 1.0000\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 0.0230 - acc: 1.0000\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 4s 557us/step - loss: 0.0162 - acc: 1.0000\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 4s 552us/step - loss: 0.0115 - acc: 1.0000\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 4s 554us/step - loss: 0.0082 - acc: 1.0000\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 0.0059 - acc: 1.0000\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 4s 552us/step - loss: 0.0043 - acc: 1.0000\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 4s 551us/step - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 4s 552us/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 4s 558us/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 8.6867e-04 - acc: 1.0000\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 4s 552us/step - loss: 6.3311e-04 - acc: 1.0000\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 4s 551us/step - loss: 4.6127e-04 - acc: 1.0000\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 3.3633e-04 - acc: 1.0000\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 2.4546e-04 - acc: 1.0000\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 1.7901e-04 - acc: 1.0000\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 4s 552us/step - loss: 1.3058e-04 - acc: 1.0000\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 4s 551us/step - loss: 9.5293e-05 - acc: 1.0000\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 6.9613e-05 - acc: 1.0000\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 4s 554us/step - loss: 5.0901e-05 - acc: 1.0000\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 3.7181e-05 - acc: 1.0000\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 2.7149e-05 - acc: 1.0000\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 1.9831e-05 - acc: 1.0000\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 1.4502e-05 - acc: 1.0000\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 4s 555us/step - loss: 1.0618e-05 - acc: 1.0000\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 7.7844e-06 - acc: 1.0000\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 5.7099e-06 - acc: 1.0000\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 4s 546us/step - loss: 4.1961e-06 - acc: 1.0000\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 4s 545us/step - loss: 3.0928e-06 - acc: 1.0000\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 4s 545us/step - loss: 2.2865e-06 - acc: 1.0000\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 1.6994e-06 - acc: 1.0000\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 4s 546us/step - loss: 1.2686e-06 - acc: 1.0000\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 4s 552us/step - loss: 9.5356e-07 - acc: 1.0000\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 7.2372e-07 - acc: 1.0000\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 5.5565e-07 - acc: 1.0000\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 4s 546us/step - loss: 4.3417e-07 - acc: 1.0000\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 3.4377e-07 - acc: 1.0000\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 2.7764e-07 - acc: 1.0000\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 2.3164e-07 - acc: 1.0000\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 1.9395e-07 - acc: 1.0000\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 1.6983e-07 - acc: 1.0000\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 4s 540us/step - loss: 1.5256e-07 - acc: 1.0000\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 1.3199e-07 - acc: 1.0000\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 1.2824e-07 - acc: 1.0000\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 1.1973e-07 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 4s 539us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 4s 551us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 4s 551us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 4s 552us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 4s 554us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 4s 557us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 4s 546us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 4s 542us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 4s 546us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 4s 551us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 4s 551us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 5s 566us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 4s 561us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 4s 561us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 4s 558us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 4s 558us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 4s 554us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 4s 562us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 4s 555us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 4s 546us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 4s 554us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 4s 545us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 1.0392e-07 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 4s 552us/step - loss: 1.0392e-07 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2e5577e7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "cuBtmT1TE9K9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Prediciting test dataset accuracy\n",
        "\n",
        "y_pred=Classifier.predict(x_test)#here we are checking with test data\n",
        "y_pred=(y_pred>0.5)#predict function will give output in form of probability but inorder to use cm we need the out put in form of yes/no thus we have set a threshold here of 50%\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g7_Khe3Nnc1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "552bf120-4d51-4e8c-82e0-af2d5d8ae373"
      },
      "cell_type": "code",
      "source": [
        "'''to predict if the following customer will leave the bank\n",
        "geog:France\n",
        "Credit score:600\n",
        "Gender:Male\n",
        "Age:40\n",
        "Tenure:3\n",
        "Balance:60000\n",
        "Is active member:Yes\n",
        "Has credit card:Yes\n",
        "Number of products:2\n",
        "Estimates Salary:50000'''\n",
        "new_prediction=Classifier.predict(sc.transform(np.array([[0.0,0,600,1,3,60000,1,1,2,50000]])))#here we are checking with test data\n",
        "new_predictiond=(new_prediction>0.5)\n",
        "\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to predict if the following customer will leave the bank\\ngeog:France\\nCredit score:600\\nGender:Male\\nAge:40\\nTenure:3\\nBalance:60000\\nIs active member:Yes\\nHas credit card:Yes\\nNumber of products:2\\nEstimates Salary:50000'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "-i6JdCJ8owvP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#if the acc from cm is similar to the accuracy from training data then we can say tat the model is right \n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_pred,y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M31luOsS96cv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "8ace9df4-5068-4380-8f2c-194f14f598a6"
      },
      "cell_type": "code",
      "source": [
        "#Kfold cross validation is used when we get different accuracy each time we run the model\n",
        "#kfold will return the relevant accuracy of an ANN using cross_val_score\n",
        "#k fold will also tell us how many biasnes is there and how many variance is there\n",
        "#Now we will use Keras with sklearn using \n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.cross_validation import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_classifier():\n",
        "  Classifier=Sequential()\n",
        "  Classifier.add(Dense(output_dim=6,init='uniform', activation='relu', input_dim=11))\n",
        "  Classifier.add(Dense(output_dim=6,init='uniform', activation='relu'))\n",
        "  Classifier.add(Dense(output_dim=1,init='uniform', activation='sigmoid'))\n",
        "  Classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return Classifier\n",
        "#estamitor is an argument that is used to fit the data\n",
        "#cv gives us the option to assign how many folds we want \n",
        "# n_jobs=-1, n_jobs allows us to specify the no of cpu's used for computation & -1 mean all cpu\n",
        "Classifier = KerasClassifier(build_fn=build_classifier, batch_size=10, nb_epoch=100)\n",
        "accuracies=cross_val_score(estimator=Classifier,X=x_train,y=y_train, cv=10, n_jobs=-1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 11s 2ms/step - loss: 0.2513 - acc: 0.9331\n",
            "7200/7200 [==============================] - 11s 2ms/step - loss: 0.2510 - acc: 0.9318\n",
            "800/800 [==============================] - 0s 428us/step\n",
            "800/800 [==============================] - 0s 448us/step\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 8s 1ms/step - loss: 0.2785 - acc: 0.8429\n",
            "7200/7200 [==============================] - 8s 1ms/step - loss: 0.2776 - acc: 0.8440\n",
            "800/800 [==============================] - 0s 453us/step\n",
            "800/800 [==============================] - 0s 411us/step\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 8s 1ms/step - loss: 0.2744 - acc: 0.8939\n",
            "7200/7200 [==============================] - 8s 1ms/step - loss: 0.2743 - acc: 0.8950\n",
            "800/800 [==============================] - 0s 480us/step\n",
            "800/800 [==============================] - 0s 476us/step\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 8s 1ms/step - loss: 0.2383 - acc: 0.9494\n",
            "7200/7200 [==============================] - 8s 1ms/step - loss: 0.2364 - acc: 0.9515\n",
            "800/800 [==============================] - 0s 550us/step\n",
            "800/800 [==============================] - 0s 489us/step\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 8s 1ms/step - loss: 0.2292 - acc: 0.9299\n",
            "7200/7200 [==============================] - 8s 1ms/step - loss: 0.2276 - acc: 0.9347\n",
            "800/800 [==============================] - 0s 507us/step\n",
            "800/800 [==============================] - 0s 492us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lJv1KydnTheq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ec3b4e61-8fba-4b93-86de-765292f7c152"
      },
      "cell_type": "code",
      "source": [
        "mean=accuracies.mean()\n",
        "variance=accuracies.std()\n",
        "print(mean)\n",
        "print(variance)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xAchn_ZZWsUr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#DropRegulazition, it is used when the model is overfiting \n",
        "#in overfitting the result in test is better than train \n",
        "#another method to find out about overfitting by checking high variance\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nLLpEy7qmzEX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #Tunning the hyperparameters using GridSearchCV\n",
        "# #gridsearcg will finout the best hyperparameters for tunning the model\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.cross_validation import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_classifier():\n",
        "  Classifier=Sequential()\n",
        "  Classifier.add(Dense(output_dim=6,init='uniform', activation='relu', input_dim=11))\n",
        "  Classifier.add(Dense(output_dim=6,init='uniform', activation='relu'))\n",
        "  Classifier.add(Dense(output_dim=1,init='uniform', activation='sigmoid'))\n",
        "  Classifier.compile(optimizer='optimizer',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return Classifier\n",
        "\n",
        "Classifier = KerasClassifier(build_fn=build_classifier, batch_size=10, nb_epoch=100)\n",
        "accuracies=cross_val_score(estimator=Classifier,X=x_train,y=y_train, cv=10, n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "amD48S4Hpisf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#creating dictoniery with all the hyperparameters that  we want to optimise\n",
        "parameters={'batch_size':[25,32],\n",
        "            'nb_epoch':[100,500],\n",
        "           'optimizer':['adam','rmsprop']}\n",
        "grid_search=GridSearchCV(estimator=Classifier,\n",
        "                        param_grid=parameters,\n",
        "                        scoring='accuracy',\n",
        "                        cv=10)#here the dict will contain all the combinations that we want to try\n",
        "grid_search=grid_search.fit(x_train,y_train)#fitting the changed parameters to the training set\n",
        "best_parameters=grid_search.best_params_\n",
        "best_accuracy=grid_search.best_score_"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}